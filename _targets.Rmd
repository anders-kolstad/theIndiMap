---
title: "IndiMap plots and analyses"
output: html_document
---

```{r setup, include = FALSE}
knitr::opts_chunk$set(collapse = TRUE, comment = "#>")
```

This report will

- compile indicator profiles `"/data/indicatorProfiles/"` and publication profiles `"/data/pulicationProfiles/"` into long format
- Perform resampling to craete dummy data
- Create plots and summary statistics


<!-- Target Markdown is a powerful R Markdown interface for reproducible analysis pipelines, and the chapter at https://books.ropensci.org/targets/markdown.html walks through it in detail. This R Markdown report the example from the chapter. Try it out in both interactive and non-interactive modes, either by running the code chunks in different ways or setting the `tar_interactive` chunk option. -->

# Packages

Here are the required packages

```{r, eval = FALSE}
install.packages(c("tidyverse", "DT"))
```


```{r, echo=T, warning=F, message=F}
library(targets)
library(tidyverse)
library(DT)
```


```{targets setup-targets, tar_globals=TRUE }
tar_option_set(packages = c("tidyverse", "dplyr", "purrr", "readr", "tidyr")) # I had to mention dplyr, purrr ect even though they are included in tidyverse.
options(tidyverse.quiet = TRUE)
```


```{r, echo=F}
#Remove R scripts from previous non-interactive runs
tar_unscript()
tar_destroy()

```


# Globals

We first define some global options/functions common to all targets. The function below plots a histogram of ozone concentrations, and our histogram target will need it.

```{targets example-globals, tar_globals = TRUE}
#| tar_interactive: FALSE

create_hist <- function(data) {
  ggplot(data) +
    geom_histogram(aes(x = Ozone), bins = 12) +
    theme_gray(24)
}
```

Here's a function to read all the CSV's and compile them in a long format.
We also take the file name and add that to the data set.

```{targets compile, tar_globals = TRUE}
##| tar_interactive: FALSE
compile_profiles <- function(files) {
  files |>
    set_names(basename) |>
    map(read.csv) %>%
  list_rbind(names_to = "fileName") |>
  tidyr::pivot_wider(names_from = parameter, values_from = value)}
```

# Targets
## Import data
Our first target reads in all the file names in `data/publicationProfiles` and stores them in a single object (`ppls`), which we can then monitor for updates.

```{targets pp-ls}
##| tar_interactive: FALSE
tar_target(ppls, 
           list.files("data/publicationProfiles", full.names = T), 
           cue = tar_cue(mode = "thorough"), 
           format="file",
           packages = "tidyverse")
```

Then we import these files and compile them into long format using `compile_profiles()`.


```{targets pp-import}
##| tar_interactive: FALSE
tar_target(publications_imported, compile_profiles(ppls),
           packages = "tidyverse")
```

Then the same for `data/indicatorProfiles`.

```{targets ip-ls}
##| tar_interactive: FALSE
tar_target(ipls, 
           list.files("data/indicatorProfiles", full.names = T), 
           cue = tar_cue(mode = "thorough"), 
           format="file",
           packages = "tidyverse")
```

Then we import these files

```{targets ip-import}
##| tar_interactive: FALSE
tar_target(indicators_imported, compile_profiles(ipls),
           packages = "tidyverse")
```



## Resample and create dummy data
Let's take `import_indicators` and resample it to populate a dummy data set which we can use to write generic code with.

```{targets scramble, tar_globals=T}
##| tar_interactive: FALSE
scramble_rows <- function(data) {
  data[sample(1:nrow(data), 150, replace = T),]
}

```

```{r}
indicators_scrambled <- scramble_rows(indicators_imported)
```


There are some columns that have multiple-choice fields separated with `|`.
For the publication profiles it's only pDirective, but this one is not so interesting, so I will ignore this for now.
In the indicator profiles we have:

```{r}
mc <- c("iContinent", "iCountry")
```

To scramble these we need a separate approach compared to just re-sampling rows.
Let us melt the data and scramble the relevnat fields, and cast it again.
```{r}
test <- indicators_imported |> 
  select(any_of(c("fileName", "iContinent", "iCountry"))) |>
  pivot_longer(cols = -fileName) |>
  separate_longer_delim(cols = value, delim=" | ") |>
  pivot_wider(id_cols = any_of("fileName"), id_expand = T)
  
```



```{targets splitMS, tar_globals=T}
splitMS <- function(x) {
  x |>
    pivot_longer()
}

#%>%
#    mutate(across(mc, ~str_split(., pattern = " | ")))
```

```{r}

test <- for(i in mc) {
  #print(i)
  #print(indicators_scrambled[1:15,i])
  vect <- str_split(indicators_scrambled[,i], " | ")
}
```



Set the `tar_simple` chunk option to `TRUE` to define a single target with the command in the code chunk. The chunk below only contains `biglm(Ozone ~ Wind + Temp, data)` in the source, but because `tar_simple` is `TRUE`, it is shorthand for `tar_target(name = fit, command = biglm(Ozone ~ Wind + Temp, data))`. All other arguments to `tar_target()` are set to their default values (configurable with `tar_option_set()`).

```{targets fit, tar_simple = TRUE}
biglm(Ozone ~ Wind + Temp, data)
```

# Pipeline

If you ran all the `{targets}` chunks in non-interactive mode, then your R scripts are set up to run the pipeline.

```{r}
tar_make()
```

# Output
<!-- You can retrieve results from the `_targets/` data store using `tar_read()` or `tar_load()`. -->

## Raw data tables
```{r publications-dt, echo=FALSE}
DT::datatable(tar_read(publications_imported),
              options = list(
                pageLength = 5))
```

```{r indicators-dt, echo=F}
DT::datatable(tar_read(indicators_imported),
              options = list(
                pageLength = 5))
```



## DAG
The `targets` dependency graph helps your readers understand the steps of your pipeline at a high level.

```{r}
tar_visnetwork()
```


